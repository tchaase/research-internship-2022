{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e6babef",
   "metadata": {},
   "source": [
    "# Linear model \n",
    "\n",
    "Previously, the data-set has been explored. In the following, the linear model will be developed. While working on this originally, just before the linear model was started, I attempted the preprocessing. This is outlined in the preprocessing section.\n",
    "\n",
    "\n",
    "These are the preprocessing and quality control pipelines used:\n",
    "\n",
    "Quality controle was performed using the [Magnetic Resoncance Imaging Quality Controle pipeline](https://mriqc.readthedocs.io/en/latest/) (22.0.6). \n",
    "\n",
    "The preprocessing was performed using [fMRI-Prep](https://fmriprep.org/en/stable/) (20.2.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a989a9a8",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of things I need later:\n",
    "import os\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show, plot_glass_brain\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602617cb",
   "metadata": {},
   "source": [
    "Fistly I will load a preprocessed image. Then, going from the previously explored event files, I will briefly mention the experimental paradigm again. These will then be used for a generalized linear model (GLM).\n",
    "\n",
    "I will first do the linear model for subject 6 to see if everything works (this subject was used as an example as it was the first participant with data for all runs).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File paths\n",
    "file_path = \"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data\"\n",
    "fmri_img_run1_sub06_path = os.path.join(file_path, \"outputs/fmri-prep_20.2.3-2\", \"sub-06\", \"sub-06_task-scene_run-01_desc-preproc_bold.nii.gz\")\n",
    "anat__img_run1_sub06_path = os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-06\", \"sub-06_task-scene_run-01_desc-preproc_T1w.nii.gz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "806e4967",
   "metadata": {},
   "source": [
    "I have now the file paths to the mri images. Now I still need the event files to define respective contrasts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_run1_sub06_path = os.path.join(file_path,\"ds003707\", \"sub-06\", \"func\", \"sub-06_task-scene_run-01_events.tsv\")\n",
    "\n",
    "import pandas as pd\n",
    "events_run1_sub06 = pd.read_table(events_run1_sub06_path)\n",
    "\n",
    "events_run1_sub06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a30e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_run1_sub06 = events_run1_sub06[[\"onset\", \"duration\", \"trial_type\"]]\n",
    "for i, row in events_run1_sub06.iterrows():\n",
    "    events_run1_sub06[\"trial_type\"][i] = events_run1_sub06[\"trial_type\"][i].replace('1_', 'Learned_')\n",
    "    events_run1_sub06[\"trial_type\"][i] = events_run1_sub06[\"trial_type\"][i].replace('2_', 'Learned_')\n",
    "    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0faca56b",
   "metadata": {},
   "source": [
    "Each trial has a certain onset, the same duration and then the response is either correct or not correct. \n",
    "We also see that there is a certain response time - if this is failed the trial is listed to be `0.0` i.e. not correct. \n",
    "\n",
    "\n",
    "Now, lets generate a design matrix with these event files. Recall that a 'design matrix' is a matrix that contains the explanatory variables. Here, the explanatory variables also involes the regressors that are the result of the previously mentioned pipelines!\n",
    "\n",
    "## First-Level Model\n",
    "\n",
    "First, before I can generate a `FirstLevelModel`, I need to extract the repetion time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "#Now I need the TR and other parameters. I previously extracted them using the 'pybids module! Here I will take also show a different attempt:\n",
    "\n",
    "import nibabel as nib ;\n",
    "\n",
    "fmri_img_run1_sub06 = nib.load(fmri_img_run1_sub06_path);\n",
    "#The get_zooms function contains voxel size with the 4th entry being the time, this is therefore the repetiton time!\n",
    "fmri_img_run1_sub06.header.get_zooms()[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cfd5ce",
   "metadata": {},
   "source": [
    "Knowing the repition time, we can set up the `FirstLevelModel`.\n",
    "\n",
    "Briefly explained, I understand a first level model as a first step used to generate the linear models later - there are certain things like the haemondynamic response that needs to be modelled, which will be done in this first step!\n",
    "\n",
    "Here is an explanation on the parameters:\n",
    "- `T_r` refers to the repetion time, this was extracted above. \n",
    "- `Drift mode`: It's a `cosine functio` that aims to remove effects of heart rate etc. The standard setting here is 1/128 Hz. In the design matrix this will end up as a column with almost no change in color, only very slight drift!\n",
    "- The `hrf-model` part specifies the`hemodynamic response model`: The event file has certain events, but this needs to be converted into a [\"reference BOLD signal for the design matrix\"](https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_first_level_details.html). Here the basic wasn't choosen, but the `spm`. This stands for statistical parametric map. In contrast to the basic the undershoot following the haemondynamic response is said to be weaker here.\n",
    "- Fruthermore, a `high pass filter` can be applied. The high pass filter will let [higher frequencies pass](https://www.brainvoyager.com/bv/doc/UsersGuide/Preprocessing/TemporalHighPassFiltering.html), the cut-off here is set to another value than the standard! What does this mean? I will have an additional confound with the lower frequencies, them being included in the model instead of them being removed!\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "- `noise_model`: There are different options for noise models. The `ar1` is the preset noise model. A ordinary least squared approach, autoregressive approaches of higher order or other models could have been used. \n",
    "&nbsp;\n",
    "\n",
    "\n",
    "- I don't want the signal to be scaled, so this is set to false!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8bf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=2.0,\n",
    "                           noise_model='ar1',\n",
    "                           hrf_model='spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=1./128,\n",
    "                           signal_scaling=False,\n",
    "                           minimize_memory =  False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3373979",
   "metadata": {},
   "source": [
    "This model still lacks the confounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "confounds_run1_sub06 = pd.read_csv(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-06\", \"sub-06_task-scene_run-01_desc-confounds.tsv\"), \n",
    "                                  delimiter = '\\t')\n",
    "#The delimiter needs to be set to \\t as it uses tab to differentiate different entries. \n",
    "\n",
    "column_names = list(confounds_run1_sub06.columns.values)\n",
    "column_names.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196380d",
   "metadata": {},
   "source": [
    "Only a portion of the entries are needed here. \n",
    "\n",
    "The following are extracted, following the recommedation from the [fmriprep-doc](https://fmriprep.org/en/stable/outputs.html#confounds). \n",
    "- The parameters of head motion, i.e. the transverse and rotational movements. `trans_x`, `trans_y`, `trans_z`, `rot_x`, `rot_y`, `rot_z`.\n",
    "\n",
    "&nbsp;\n",
    "The following three are copy-pastad from said website:\n",
    "- `csf - the average signal within anatomically-derived eroded CSF mask`\n",
    "- `white_matter - the average signal within the anatomically-derived eroded WM masks`\n",
    "-  `global_signal - the average signal within the brain mask`\n",
    "\n",
    "- the rmsd - this also takes head motion into account but using a different statistical approach.\n",
    "- framewise_displacement - another classic measure of movement. \n",
    "\n",
    "As a high-pass filter is included, I will not include regressors for signal drift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds_glm_run1_sub06 = confounds_run1_sub06[['white_matter', 'global_signal', 'framewise_displacement','csf', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'rmsd']].replace(np.nan, 0)\n",
    "confounds_glm_run1_sub06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682809d2",
   "metadata": {},
   "source": [
    "I have now specified the confounds I will need. \n",
    "\n",
    "\n",
    "Below, there is one step that only works with never versions of nilearn (0.9.2. and newer) but is not necessary here. The event files only start after 5 volumes, meaining with a repetition time of 2 after 10 seconds. \n",
    "A sample mask can be used to remove them, which is an option I am not going to do to make it easier to analyse a lot of files later fast and thus remove one unnecessary analyses steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.image as nli\n",
    "\n",
    "#Loading the image to get the amount of volumes.\n",
    "sub06_run1_bold = nli.load_img(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-06\", \"sub-06_task-scene_run-01_desc-preproc_bold.nii.gz\"))\n",
    "sub06_run1_bold_mask = np.arange((sub06_run1_bold.get_fdata().shape[3]))[5:]  \n",
    "#creating an array with the amount entries equaling volumes except the first 10 seconds / 5 volumes. \n",
    "# just another way besides looking at the .json! Although a one with longer loading times!\n",
    "sub06_run1_bold_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbf3d6",
   "metadata": {},
   "source": [
    "Now lets run the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm_run1_sub06 = fmri_glm.fit(fmri_img_run1_sub06_path, events = events_run1_sub06, \\\n",
    "                                          # sample_masks = sub06_run1_bold_mask, \\ removed\n",
    "                                          confounds = confounds_glm_run1_sub06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = fmri_glm_run1_sub06.design_matrices_[0]\n",
    "\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "plot_design_matrix(design_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2711d2b",
   "metadata": {},
   "source": [
    "There was 36 objects or scenes. Each was repeated twice per run. There were 18 object scene pairmates as explained in the data exploration. \n",
    "\n",
    "Let's save this design matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'results'\n",
    "os.chdir(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/\")\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "\n",
    "from os.path import join\n",
    "plot_design_matrix(design_matrix, output_file=join(outdir, 'design_matrix.png'))\n",
    "\n",
    "outdir_path = os.path.join(file_path, \"outputs\", \"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc156df",
   "metadata": {},
   "source": [
    "I am already creating an output folder for participant 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a80ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(outdir_path, \"sub-06\")):\n",
    "    os.mkdir(os.path.join(outdir_path, \"sub-06\"))\n",
    "else: \n",
    "    print(\"This one already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a60e7",
   "metadata": {},
   "source": [
    "To ensure this works, I want to inspect the expected response for a random item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(design_matrix['Learned_A2']) \n",
    "plt.xlabel('scan')\n",
    "plt.title('Expected Response for Image A2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "928d3616",
   "metadata": {},
   "source": [
    "Thus far everything seems to work as intended. \n",
    "\n",
    "Now I want to identify voxels that have significant effects within the next section.\n",
    "\n",
    "## Detection of Significant Voxels\n",
    "\n",
    "Firstly, I will need to get the betas for every voxel. To achieve this, I need to first get the contrasts. These will require some data wrangling, which will be done in the following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ffc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "array_learned = np.array([0]*design_matrix.shape[0])\n",
    "                            \n",
    "conditions = {\n",
    "    'active - Learned': np.array([0]*design_matrix.shape[1]),\n",
    "    'active - Foil':   np.array([0]*design_matrix.shape[1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d669ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for col in design_matrix:\n",
    "    if \"foil\" in col:     #Creating the contrast for the lure images. \n",
    "        conditions['active - Foil'][i] = 1\n",
    "    elif \"Learned_A\" in col: #Creating the contrast for the learned images.\n",
    "        conditions['active - Learned'][i] = 1\n",
    "    elif \"Learned_B\" in col: #Creating the contrast for the learned images.\n",
    "        conditions['active - Learned'][i] = 1\n",
    "    i = i+1   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5439bf",
   "metadata": {},
   "source": [
    "Let's have a look at the conditions and see if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a27222",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f73009",
   "metadata": {},
   "source": [
    "Above, I have created some first contrasts to test the rest of the glm. If this works, I may change it according to what I wanted to do initially!\n",
    "\n",
    "Here is the contrast for the learned images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233915b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(conditions['active - Learned'], design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b18a5",
   "metadata": {},
   "source": [
    "Here is the contrast for the lures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc595694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_contrast_matrix\n",
    "plot_contrast_matrix(conditions['active - Foil'], design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e8da7c",
   "metadata": {},
   "source": [
    "The contrast I would like to take is the learned images vs the foils. The contrasts are therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5163ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learned_vs_foil = conditions['active - Learned'] - conditions['active - Foil']\n",
    "plot_contrast_matrix(active_learned_vs_foil, design_matrix=design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b53879",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_map = fmri_glm_run1_sub06.compute_contrast(active_learned_vs_foil,\n",
    "                                    output_type='effect_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f05c5d",
   "metadata": {},
   "source": [
    "This shows the estimated effects without involving any corrections for the variation. \n",
    "\n",
    "The next plot contains the z-map. Here, we use z scores that are approximated by t-values. As mentioned before, the functional image is cut off. The treshold is choosen arbitraily following the preset value in nilearn's example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map_sub06_run1 = fmri_glm_run1_sub06.compute_contrast(active_learned_vs_foil,\n",
    "                                  output_type='z_score')\n",
    "\n",
    "#Get the mean image\n",
    "from nilearn.image import mean_img\n",
    "mean_img_run1_sub06 = mean_img(fmri_img_run1_sub06_path)\n",
    "\n",
    "plot_stat_map(z_map_sub06_run1, bg_img=mean_img_run1_sub06, threshold=3.0,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='active -  (Z>3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b47cc41",
   "metadata": {},
   "source": [
    "This is the z-map with a treshold of the false-discovery rate: It's set to 0.001 for all the significant voxels together. This is what's meant by `fpr`, it stands for the control for the false recovery rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm import threshold_stats_img\n",
    "_, threshold = threshold_stats_img(z_map_sub06_run1, alpha=.001, height_control='fpr')\n",
    "print('Uncorrected p<0.001 threshold: %.3f' % threshold)\n",
    "plot_stat_map(z_map_sub06_run1, bg_img=mean_img_run1_sub06, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,title= 'Learned vs foil (p<0.001)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe5865",
   "metadata": {},
   "source": [
    "And here I correct for multiple comperison. The family wise error is corrected using the Bonferroni-correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshold = threshold_stats_img(\n",
    "    z_map_sub06_run1, alpha=.05, height_control='bonferroni')\n",
    "print('Bonferroni-corrected, p<0.05 threshold: %.3f' % threshold)\n",
    "plot_stat_map(z_map_sub06_run1, bg_img=mean_img_run1_sub06, threshold=threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Learned vs foil (p<0.05, corrected)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98fcbc",
   "metadata": {},
   "source": [
    "Having displayed the different options, I am going for the following:\n",
    "  - I am interested in smaller clusters, for example within the hippocampus. I will therefore choose a smaller cluster treshold. \\\n",
    "      &rarr; Furthermore, FDR-correction should, correct for the increase in voxels with no exclusion of smaller clusters.     \n",
    "    \n",
    "  - I do want to correct for the multiple comparisons, as a trade-off between being rather conservative (Bonferonni) and a rather liberal approach (controlling for the false-positive rate), I want to control for the proportion of false discoveries among the deteced values. \n",
    "  \n",
    "The correction for the false discovery rate controls for the the number of false positives among the subset of voxels that are significant (Genovese, 2002). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_map, threshold = threshold_stats_img(z_map_sub06_run1, alpha=.001, height_control='fpr', cluster_threshold= 10)\n",
    "print('False Discovery rate = 0.001 threshold: %.3f' % threshold)\n",
    "plot_stat_map(clean_map, bg_img=mean_img_run1_sub06, threshold = threshold,\n",
    "              display_mode='z', cut_coords=3, black_bg=True,\n",
    "              title='Learned vs foil (fdr = 0.001, cluster > 10 voxels)')\n",
    "plt.show()\n",
    "\n",
    "#Saving the z-map for future use:\n",
    "z_map_sub06_run1.to_filename(os.path.join(outdir, 'sub-06_task-scene_run-01_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3b366d",
   "metadata": {},
   "source": [
    "Let's extract any significant voxels from the above image and look at them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "table = get_clusters_table(z_map_sub06_run1, stat_threshold=threshold,\n",
    "                           cluster_threshold=10)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bce7d3",
   "metadata": {},
   "source": [
    "As seen above, with the conservative approach with the family-wise error correction, there is no cluster that appears significant (at least with the treshold set right now). I will need to see if there are any errors above etc. \n",
    "\n",
    "Non of the clusters are significant - but with the following bit I could get more information on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe46116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlasreader import create_output\n",
    "create_output(os.path.join(outdir, \"sub-06_task-scene_run-01_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.nii.gz\"),\n",
    "              cluster_extent=10, voxel_thresh=threshold)\n",
    "\n",
    "            #With the zmap, the previously defined treshold and the zmap, this function creates multiple files that\n",
    "            #allow to explore the exploration of the z-map. \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9baf16",
   "metadata": {},
   "source": [
    "The peak is the value in each cluster with the highest signal value, as well as information regarding this peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_info_sub_06_run_1 = pd.read_csv(os.path.join(outdir, \"sub-06_task-scene_run-01_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap_peaks.csv\"))\n",
    "\n",
    "peak_info_sub_06_run_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37df71b",
   "metadata": {},
   "source": [
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(os.path.join(outdir, \"sub-06_task-scene_run-01_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d63e54",
   "metadata": {},
   "source": [
    "Having explored this all in detail, let's take the short-cut of just using the glm report function and see what this function comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import make_glm_report\n",
    "\n",
    "report = make_glm_report(fmri_glm_run1_sub06, contrasts= active_learned_vs_foil,\n",
    "                         bg_img=mean_img_run1_sub06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfdd78e",
   "metadata": {},
   "source": [
    "Let's lastly look at the R-squared to see how much variance is explained. The RÂ² is baded on the glm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8481ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "plotting.plot_stat_map(fmri_glm_run1_sub06.r_square[0], bg_img=mean_img_run1_sub06, threshold=.1,\n",
    "                       display_mode='z', cut_coords=7, cmap='magma');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8879f106",
   "metadata": {},
   "source": [
    "## Extending the GLM to the Other Runs\n",
    "\n",
    "First I am loading all fmri-images and I am concatenating them. This first step will generate a list with all file paths for one participant. \n",
    "\n",
    "I will just do this for participant 6 in the beginning, and then create a `for` loop which extends this to every participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'28', '34', '35', '36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d0504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show, plot_glass_brain\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "import nilearn.image as nli\n",
    "import pandas as pd \n",
    "\n",
    "file_path = \"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef91902",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_test = '36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab7b2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "fmri_img_path= []\n",
    "fmri_img_path_single = []\n",
    "os.chdir(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/fmri-prep_20.2.3-2/\")\n",
    "for i in os.listdir(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/fmri-prep_20.2.3-2/sub-%s\" %(subject_test)):\n",
    "    file_name = i\n",
    "    if file_name.endswith(\"bold.nii.gz\") and \"scene\" in file_name: \n",
    "         fmri_img_path.append(file_name)\n",
    "    else:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f6ecb",
   "metadata": {},
   "source": [
    "Now, I have all the image paths. But the actual images still need to be attached to each other! This way, the confunds that do not change acrosss the runs can be modelled as continous.\n",
    "\n",
    "Now, I should also append the confounds to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8247d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confounds = []\n",
    "for run in ['01', '03', '04', '05', '06', '07']:\n",
    "    # read in the confounds\n",
    "    confounds_run = pd.read_csv(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject_test), \"sub-%s_task-scene_run-%s_desc-confounds.tsv\" %(subject_test, run)), \n",
    "                            delimiter = '\\t')\n",
    "    \n",
    "    # restrict the to be included confounds to a subset\n",
    "    confounds_run_glm = confounds_run[['white_matter', 'global_signal', 'framewise_displacement','csf', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'rmsd']].replace(np.nan, 0)\n",
    "    confounds.append(confounds_run_glm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1d5aa",
   "metadata": {},
   "source": [
    "Now the event files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5f310fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 01\n",
      "Run 03\n",
      "Run 04\n",
      "Run 05\n",
      "Run 06\n",
      "Run 07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "for run in ['01', '03', '04', '05', '06', '07']:\n",
    "    # read in the events\n",
    "    events_run = pd.read_table(os.path.join(file_path,\"ds003707\", \"sub-%s\" %(subject_test), \"func\", \"sub-%s_task-scene_run-%s_events.tsv\" %(subject_test, run)))\n",
    "    \n",
    "    #perform operations on the events table to make it fit the glm\n",
    "    events_run = events_run[[\"onset\", \"duration\", \"trial_type\"]]\n",
    " \n",
    "    print(\"Run %s\" %(run))\n",
    "    \n",
    "    events_runs_cor_name = events_run\n",
    "    for i, row in events_run.iterrows():\n",
    "        events_runs_cor_name[\"trial_type\"][i] = events_run[\"trial_type\"][i].replace('1_', 'Learned_')\n",
    "        events_runs_cor_name[\"trial_type\"][i] = events_run[\"trial_type\"][i].replace('2_', 'Learned_')\n",
    "\n",
    "    events.append(events_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d066c1",
   "metadata": {},
   "source": [
    " To use the [make_first_level_design_matrix](https://nilearn.github.io/dev/modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html), I need to also define the frame rates. The repetition time I already know, I need to find out the number of scans to find out the frame-rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "569a71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "T_R = 2.0\n",
    "n_scans = 177\n",
    "frame_times = arange(n_scans)*T_R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3caebc",
   "metadata": {},
   "source": [
    "Next I will get the design matrix for every run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e74fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "runs_numbered = ['01', '03', '04', '05', '06', '07']\n",
    "\n",
    "design_matrix_all_runs = []\n",
    "for runs_numbered , x in enumerate(runs_numbered ):\n",
    "    design_matrix = make_first_level_design_matrix(frame_times, events[runs_numbered ], \n",
    "        drift_model='cosine',\n",
    "        hrf_model='spm',\n",
    "        high_pass= 1./128, \n",
    "        add_regs= confounds[runs_numbered ])\n",
    "    design_matrix_all_runs.append(design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a74cbb",
   "metadata": {},
   "source": [
    "Now I will fit the glm. As the HRF etc. was already specified in the first_level_design_matrix, I left it out for the FirstLevelModel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6d6086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm_loop = FirstLevelModel(t_r=2.0,\n",
    "                           noise_model= 'ar1',\n",
    "                           hrf_model= 'spm',\n",
    "                           drift_model='cosine',\n",
    "                           high_pass=1./128,\n",
    "                           signal_scaling= False,\n",
    "                           minimize_memory =  True,\n",
    "                           memory = \"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/\",\n",
    "                           memory_level = 600000,\n",
    "                           verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29283aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-36_task-scene_run-01_desc-preproc_bold.nii.gz',\n",
       " 'sub-36_task-scene_run-03_desc-preproc_bold.nii.gz',\n",
       " 'sub-36_task-scene_run-04_desc-preproc_bold.nii.gz',\n",
       " 'sub-36_task-scene_run-05_desc-preproc_bold.nii.gz',\n",
       " 'sub-36_task-scene_run-06_desc-preproc_bold.nii.gz',\n",
       " 'sub-36_task-scene_run-07_desc-preproc_bold.nii.gz']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_img_path = sorted(fmri_img_path)\n",
    "fmri_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c4c7114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from sub-36_task-scene_run-01_desc-preproc_bold.nii.gz\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.masking.compute_epi_mask...\n",
      "compute_epi_mask('sub-36_task-scene_run-01_desc-preproc_bold.nii.gz', verbose=0)\n",
      "_________________________________________________compute_epi_mask - 5.2s, 0.1min\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.resampling.resample_img...\n",
      "resample_img(<nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, target_affine=None, target_shape=None, copy=False, interpolation='nearest')\n",
      "_____________________________________________________resample_img - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing run 1 out of 6 runs (go take a coffee, a big one)\n",
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158f35b400>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-01_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158f359390>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158f35b400>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 6.4s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[3903.300681, ..., 5288.416046],\n",
      "       ...,\n",
      "       [4021.747049, ..., 5324.657098]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 21 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 16.4s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[3903.300681, ..., 5288.416046],\n",
      "       ...,\n",
      "       [4021.747049, ..., 5324.657098]]), \n",
      "array([[0., ..., 1.],\n",
      "       ...,\n",
      "       [0., ..., 1.]]), noise_model='ar1', bins=100, n_jobs=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 7 seconds         \n",
      "Computing run 2 out of 6 runs (171 seconds remaining)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________run_glm - 6.9s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158efb3358>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-03_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158efb3588>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158efb3358>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 6.9s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[4174.704431, ..., 5066.732612],\n",
      "       ...,\n",
      "       [3992.244121, ..., 5109.042249]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 22 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 17.0s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[4174.704431, ..., 5066.732612],\n",
      "       ...,\n",
      "       [3992.244121, ..., 5109.042249]]), \n",
      "array([[ 0.      , ...,  1.      ],\n",
      "       ...,\n",
      "       [-0.005783, ...,  1.      ]]), noise_model='ar1', bins=100, n_jobs=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 7 seconds         \n",
      "Computing run 3 out of 6 runs (137 seconds remaining)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________run_glm - 6.6s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158f363080>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-04_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158f363278>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158f363080>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 7.1s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[4757.601328, ..., 5250.210586],\n",
      "       ...,\n",
      "       [4961.891552, ..., 5493.046136]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 22 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 17.2s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[4757.601328, ..., 5250.210586],\n",
      "       ...,\n",
      "       [4961.891552, ..., 5493.046136]]), \n",
      "array([[0., ..., 1.],\n",
      "       ...,\n",
      "       [0., ..., 1.]]), noise_model='ar1', bins=100, n_jobs=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 8 seconds         \n",
      "Computing run 4 out of 6 runs (104 seconds remaining)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________run_glm - 7.0s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158efb10f0>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-05_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158efb13c8>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158efb10f0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 7.6s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[4044.686171, ..., 5826.961737],\n",
      "       ...,\n",
      "       [4609.654677, ..., 5125.064542]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.64s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 22 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 17.6s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[4044.686171, ..., 5826.961737],\n",
      "       ...,\n",
      "       [4609.654677, ..., 5125.064542]]), \n",
      "array([[ 0.      , ...,  1.      ],\n",
      "       ...,\n",
      "       [-0.060664, ...,  1.      ]]), noise_model='ar1', bins=100, n_jobs=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 7 seconds         \n",
      "Computing run 5 out of 6 runs (69 seconds remaining)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________run_glm - 6.8s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158f2f0208>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-06_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158f2f0518>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158f2f0208>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 7.7s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[4343.225337, ..., 5031.631251],\n",
      "       ...,\n",
      "       [4805.581395, ..., 4672.248903]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 23 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 17.8s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[4343.225337, ..., 5031.631251],\n",
      "       ...,\n",
      "       [4805.581395, ..., 4672.248903]]), \n",
      "array([[ 0.      , ...,  1.      ],\n",
      "       ...,\n",
      "       [-0.052948, ...,  1.      ]]), noise_model='ar1', bins=100, n_jobs=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 8 seconds         \n",
      "Computing run 6 out of 6 runs (35 seconds remaining)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________run_glm - 7.1s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting masker computation \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker._filter_and_mask...\n",
      "_filter_and_mask(<nibabel.nifti1.Nifti1Image object at 0x7f158ef44160>, <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'high_variance_confounds': False,\n",
      "  'low_pass': None,\n",
      "  'reports': True,\n",
      "  'runs': None,\n",
      "  'smoothing_fwhm': None,\n",
      "  'standardize': False,\n",
      "  'standardize_confounds': True,\n",
      "  't_r': 2.0,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=600000, memory=Memory(location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib), verbose=1, confounds=None, sample_mask=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image('sub-36_task-scene_run-07_desc-preproc_bold.nii.gz')\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: JobLibCollisionWarning: Cannot detect name collisions for function 'nifti_masker_extractor'\n",
      "  memory_level=memory_level)(imgs)\n",
      "WARNING:root:[MemorizedFunc(func=<nilearn.maskers.nifti_masker._ExtractionFunctor object at 0x7f158ef44278>, location=/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/cache/joblib)]: Clearing function cache identified by nilearn/maskers/nifti_masker/nifti_masker_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.maskers.nifti_masker.nifti_masker_extractor...\n",
      "nifti_masker_extractor(<nibabel.nifti1.Nifti1Image object at 0x7f158ef44160>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:96: UserWarning: Persisting input arguments took 2.60s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  memory_level=memory_level)(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________nifti_masker_extractor - 7.6s, 0.1min\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.signal.clean...\n",
      "clean(array([[3872.197248, ..., 5514.584817],\n",
      "       ...,\n",
      "       [3914.581444, ..., 4754.212353]]), detrend=False, standardize=False, standardize_confounds=True, t_r=2.0, low_pass=None, high_pass=None, confounds=None, sample_mask=None, runs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/base_masker.py:119: UserWarning: Persisting input arguments took 0.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  runs=runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________clean - 1.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/maskers/nifti_masker.py:486: UserWarning: Persisting input arguments took 2.62s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  dtype=self.dtype\n",
      "Masker took 23 seconds       \n",
      "Performing GLM computation\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________filter_and_mask - 17.7s, 0.3min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.glm.first_level.first_level.run_glm...\n",
      "run_glm(array([[3872.197248, ..., 5514.584817],\n",
      "       ...,\n",
      "       [3914.581444, ..., 4754.212353]]), \n",
      "array([[0., ..., 1.],\n",
      "       ...,\n",
      "       [0., ..., 1.]]), noise_model='ar1', bins=100, n_jobs=1)\n",
      "__________________________________________________________run_glm - 6.9s, 0.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:589: UserWarning: Persisting input arguments took 0.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  bins=bins, n_jobs=self.n_jobs)\n",
      "GLM took 7 seconds         \n",
      "\n",
      "Computation of 6 runs done in 212 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject_test)))\n",
    "glm = fmri_glm_loop.fit(fmri_img_path, design_matrices = design_matrix_all_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872aaef6",
   "metadata": {},
   "source": [
    "And now lets save this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42d69e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchaase/miniconda3/envs/msc5neuro/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:657: UserWarning: One contrast given, assuming it for all 6 runs\n",
      "  warn('One contrast given, assuming it for all %d runs' % n_runs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating z maps for 36\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.masking.unmask...\n",
      "unmask(array([ 1.556498, ..., -2.32296 ]), <nibabel.nifti1.Nifti1Image object at 0x7f158f2ff358>)\n",
      "___________________________________________________________unmask - 0.1s, 0.0min\n",
      "Saving z-maps 36, 01\n",
      "Saving z-maps 36, 03\n",
      "Saving z-maps 36, 04\n",
      "Saving z-maps 36, 05\n",
      "Saving z-maps 36, 06\n",
      "Saving z-maps 36, 07\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "array_learned = np.array([0]*design_matrix.shape[0])\n",
    "                            \n",
    "conditions = {\n",
    "    'active - Learned': np.array([0]*design_matrix.shape[1]),\n",
    "    'active - Foil':   np.array([0]*design_matrix.shape[1]),\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for col in design_matrix:\n",
    "    if \"foil\" in col:     #Creating the contrast for the lure images. \n",
    "        conditions['active - Foil'][i] = 1\n",
    "    elif \"Learned_A\" in col: #Creating the contrast for the learned images.\n",
    "        conditions['active - Learned'][i] = 1\n",
    "    elif \"Learned_B\" in col: #Creating the contrast for the learned images.\n",
    "        conditions['active - Learned'][i] = 1\n",
    "    i = i+1   \n",
    "\n",
    "active_learned_vs_foil = conditions['active - Learned'] - conditions['active - Foil']\n",
    "\n",
    "outdir_path = os.path.join(file_path, \"outputs\", \"results\")\n",
    "\n",
    "print(\"Creating z maps for %s\" %(subject_test))\n",
    "    # compute the contrast as a z-map\n",
    "z_map = glm.compute_contrast(active_learned_vs_foil,\n",
    "    output_type='z_score')\n",
    "        \n",
    "    #defining the folder, where the resulting zmap shall be stored. To make it more easily manually inspectable, a folder for each participant is created\n",
    "if not os.path.exists(os.path.join(outdir_path, \"sub-%s\" %subject_test)):\n",
    "    os.mkdir(os.path.join(outdir_path, \"sub-%s\" %subject_test))\n",
    "\n",
    "for run_test in ['01', '03', '04', '05', '06', '07']:\n",
    "    print(\"Saving z-maps %s, %s\" %(subject_test, run_test))\n",
    "    # save the z-map\n",
    "    z_map.to_filename(os.path.join(outdir_path, \"sub-%s\" %subject_test, 'sub-%s_task-scene_run-%s_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.nii.gz' %(subject_test, run_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8e8a2",
   "metadata": {},
   "source": [
    "Here is the loop to attempt this for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "fmri_img_path= []\n",
    "os.chdir(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/fmri-prep_20.2.3-2/\")\n",
    "\n",
    "for subject in ['03']:\n",
    "    print(\"Getting path for %s\" %(subject))\n",
    "    \n",
    "    #Getting the file paths\n",
    "    for i in os.listdir(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/fmri-prep_20.2.3-2/sub-%s\" %(subject)):\n",
    "        file_name = i\n",
    "        if file_name.endswith(\"bold.nii.gz\") and \"scene\" in file_name: \n",
    "             fmri_img_path.append(file_name)\n",
    "        else:\n",
    "             continue\n",
    "    fmri_img_path = sorted(fmri_img_path)\n",
    "    print(\"Getting the confounds for %s\" %(subject))            \n",
    "    #Getting and appending the confounds\n",
    "    confounds = []\n",
    "    for run in ['01', '03', '04', '05', '06', '07']:\n",
    "    # read in the confounds\n",
    "        confounds_run = pd.read_csv(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject), \"sub-%s_task-scene_run-%s_desc-confounds.tsv\" %(subject, run)), \n",
    "                            delimiter = '\\t')\n",
    "    \n",
    "    # restrict the to be included confounds to a subset\n",
    "        confounds_run_glm = confounds_run[['white_matter', 'global_signal', 'framewise_displacement','csf', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'rmsd']].replace(np.nan, 0)\n",
    "        confounds.append(confounds_run_glm)\n",
    "        \n",
    "    print(\"Getting the events for %s\" %(subject))  \n",
    "    events = []\n",
    "    for run in ['01', '03', '04', '05', '06', '07']:\n",
    "        # read in the events\n",
    "        events_run = pd.read_table(os.path.join(file_path,\"ds003707\", \"sub-%s\" %(subject), \"func\", \"sub-%s_task-scene_run-%s_events.tsv\" %(subject, run)))\n",
    "    \n",
    "        #perform operations on the events table to make it fit the glm\n",
    "        events_run = events_run[[\"onset\", \"duration\", \"trial_type\"]]\n",
    " \n",
    "        print(\"Run %s\" %(run))\n",
    "    \n",
    "        events_runs_cor_name = events_run\n",
    "        for i, row in events_run.iterrows():\n",
    "            events_runs_cor_name[\"trial_type\"][i] = events_run[\"trial_type\"][i].replace('1_', 'Learned_')\n",
    "            events_runs_cor_name[\"trial_type\"][i] = events_run[\"trial_type\"][i].replace('2_', 'Learned_')\n",
    "\n",
    "        events.append(events_run)\n",
    "    \n",
    "    \n",
    "    print(\"Creating the design-matrix for %s\" %(subject))\n",
    "    #Getting the frame rates for design matrix. \n",
    "    from numpy import arange\n",
    "    T_R = 2.0\n",
    "    fmri_img_path_single = os.path.join(\"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data/outputs/fmri-prep_20.2.3-2/sub-%s\" %(subject), fmri_img_path[1])\n",
    "    fmri_img_run = nib.load(fmri_img_path_single)\n",
    "    n_scans = fmri_img_run.shape[3]\n",
    "    frame_times = arange(n_scans)*T_R\n",
    "    \n",
    "    from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "    runs_numbered = ['01', '03', '04', '05', '06', '07']\n",
    "\n",
    "    design_matrix_all_runs = []\n",
    "    for runs_numbered , x in enumerate(runs_numbered ):\n",
    "        design_matrix = make_first_level_design_matrix(frame_times, \n",
    "            events[runs_numbered ], \n",
    "            drift_model='cosine',\n",
    "            hrf_model='spm',\n",
    "            high_pass= 1./128, add_regs= confounds[runs_numbered ])\n",
    "        design_matrix_all_runs.append(design_matrix)\n",
    "    \n",
    "    print(\"Fitting the glm for %s\" %(subject))\n",
    "    \n",
    "    #fitting the glm\n",
    "    os.chdir(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject)))\n",
    "    fmri_glm_loop_fitted = fmri_glm_loop.fit(fmri_img_path, design_matrices = design_matrix_all_runs)\n",
    "    \n",
    "    print(\"Creating z maps for %s\" %(subject))\n",
    "    # compute the contrast as a z-map\n",
    "    z_map = fmri_glm_loop_fitted.compute_contrast(active_learned_vs_foil,\n",
    "                                  output_type='z_score')\n",
    "        \n",
    "    #defining the folder, where the resulting zmap shall be stored. To make it more easily manually inspectable, a folder for each participant is created\n",
    "    if not os.path.exists(os.path.join(outdir_path, \"sub-%s\" %subject)):\n",
    "        os.mkdir(os.path.join(outdir_path, \"sub-%s\" %subject))\n",
    "    \n",
    "    print(\"Saving z-maps %s\" %(subject))\n",
    "    # save the z-map\n",
    "    z_map.to_filename(os.path.join(outdir_path, \"sub-%s\" %subject, 'sub-%s_task-scene_run-%s_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.nii.gz' %(subject, run)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70451952",
   "metadata": {},
   "source": [
    "Here is the list of all participants for the rare occasion this does not crash and I get to run all participants at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_subjects = ['03', '06', '08', '09', '10', '11', '12', '14', '19', '20', '22', '23', '24', '25', '27','28', '34', '35', '36']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df064669",
   "metadata": {},
   "source": [
    "As it seems my device is unable to handle the memory load. I am therefore going to take a shortcut in order to get to the machine learning section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/tchaase/Documents/Universitaet/Forschungsmodul/project/data\"\n",
    "for subject in ['03']:\n",
    "    print(\"Now calculating %s\" % subject)\n",
    "    mean_image \n",
    "    for run in ['01', '03', '04', '05', '06', '07']:\n",
    "        print(\"For %s, now calculating run %s\" %(subject, run))\n",
    "        #Setting the paths\n",
    "        fmri_img_path = os.path.join(file_path, \"outputs/fmri-prep_20.2.3-2\", \"sub-%s\" %(subject), \"sub-%s_task-scene_run-%s_desc-preproc_bold.nii.gz\" %(subject, run))\n",
    "        anat__img_path = os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject), \"sub-%s_task-scene_run-%s_desc-preproc_T1w.nii.gz\" %(subject, run))\n",
    "    \n",
    "        # read in the events\n",
    "        events = pd.read_table(os.path.join(file_path,\"ds003707\", \"sub-%s\" %(subject), \"func\", \"sub-%s_task-scene_run-%s_events.tsv\" %(subject, run)))\n",
    "    \n",
    "        #perform operations on the events table to make it fit the glm\n",
    "        events = events[[\"onset\", \"duration\", \"trial_type\"]]\n",
    "        for i, row in events.iterrows():\n",
    "            events[\"trial_type\"][i] = events[\"trial_type\"][i].replace('1_', 'Learned_')\n",
    "            events[\"trial_type\"][i] = events[\"trial_type\"][i].replace('2_', 'Learned_')\n",
    "    \n",
    "        # read in the confounds\n",
    "        confounds = pd.read_csv(os.path.join(file_path, \"outputs\", \"fmri-prep_20.2.3-2\", \"sub-%s\" %(subject), \"sub-%s_task-scene_run-%s_desc-confounds.tsv\" %(subject, run)), \n",
    "                                  delimiter = '\\t')\n",
    "    \n",
    "        # restrict the to be included confounds to a subset\n",
    "        confounds_glm = confounds[['white_matter', 'global_signal', 'framewise_displacement','csf', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'rmsd']].replace(np.nan, 0)\n",
    "    \n",
    "        # run the GLM\n",
    "        fmri_glm = fmri_glm.fit(fmri_img_path, events, confounds_glm)\n",
    "    \n",
    "        # compute the contrast as a z-map\n",
    "        z_map = fmri_glm.compute_contrast(active_learned_vs_foil,\n",
    "                                  output_type='z_score')\n",
    "        \n",
    "        #defining the folder, where the resulting zmap shall be stored. To make it more easily manually inspectable, a folder for each participant is created\n",
    "        if not os.path.exists(os.path.join(outdir_path, \"sub-%s\" %subject)):\n",
    "            os.mkdir(os.path.join(outdir_path, \"sub-%s\" %subject))\n",
    "        \n",
    "        # save the z-map\n",
    "        z_map.to_filename(os.path.join(outdir_path, \"sub-%s\" %test, 'sub-%s_task-scene_run-%s_space-MNI152nlin2009casym_desc-learnedvsfoil_zmap.nii.gz' %(subject, run)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea156a",
   "metadata": {},
   "source": [
    "Before I can progress further, I need to decide on how to crossvalidate. \n",
    "The stimuli are the same across runs and across people. There are two options:\n",
    "1. Use a certain number of runs and cross-validate by using runs from every participants. \n",
    "2. Use a certain amount of participants to cross-validate. \n",
    "\n",
    "As I have data for a few participants and I don't want to overfit by testing and fitting on the same participants, I choose to use a certain amount of participants to cross-validate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
